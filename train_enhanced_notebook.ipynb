{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66fb05ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENV_PY: /Users/javier/Documents/202508_DeepL_lab1_B/.venv/bin/python\n",
      "RICH_OK\n"
     ]
    }
   ],
   "source": [
    "# Kernel/env quick check: Python path and rich availability\n",
    "import sys\n",
    "print(\"ENV_PY:\", sys.executable)\n",
    "try:\n",
    "    import rich  # noqa: F401\n",
    "    print(\"RICH_OK\")\n",
    "except Exception:\n",
    "    print(\"RICH_MISSING -> installing to current kernel...\")\n",
    "    # Install into the active kernel if needed\n",
    "    %pip install -q rich\n",
    "    import rich  # noqa: F401\n",
    "    print(\"RICH_INSTALLED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecede92",
   "metadata": {},
   "source": [
    "# Enhanced PyTorch Image Classifier (Notebook)\n",
    "Interactive version of `train_enhanced.py` with MPS (Apple Silicon) support, rich progress, and evaluation.\n",
    "\n",
    "- Configure parameters in the Config cell.\n",
    "- Run the Training cell to start.\n",
    "- Results and artifacts go to `runs/<variant>/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f014796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install requirements into the current kernel environment\n",
    "# You can skip if your environment already has these.\n",
    "# !pip install -r requirements.txt\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf1613c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javier/Documents/202508_DeepL_lab1_B/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Using torch </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.8</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mUsing torch \u001b[0m\u001b[1;36m2.8\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">MPS available: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mMPS available: \u001b[0m\u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports & setup\n",
    "import os, json, time, warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "from datetime import timedelta\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import timm\n",
    "from timm.data import Mixup, create_transform\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "from timm.utils import ModelEmaV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tqdm import tqdm\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "console = Console()\n",
    "\n",
    "console.print(f'Using torch {torch.__version__}', style='cyan')\n",
    "console.print(f'MPS available: {torch.backends.mps.is_available()}', style='cyan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340195bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress tracking helper\n",
    "class TrainingTracker:\n",
    "    def __init__(self, total_epochs: int, train_batches: int, val_batches: int):\n",
    "        self.total_epochs = total_epochs\n",
    "        self.train_batches = train_batches\n",
    "        self.val_batches = val_batches\n",
    "        self.start_time = time.time()\n",
    "        self.epoch_start_time = None\n",
    "        self.train_losses = deque(maxlen=100)\n",
    "        self.val_losses = []\n",
    "        self.val_accs = []\n",
    "        self.lrs = []\n",
    "        self.best_acc = 0\n",
    "        self.best_epoch = 0\n",
    "        self.epoch_times = deque(maxlen=5)\n",
    "\n",
    "    def start_epoch(self, epoch: int):\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.current_epoch = epoch\n",
    "\n",
    "    def end_epoch(self, val_acc: float):\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        if val_acc > self.best_acc:\n",
    "            self.best_acc = val_acc\n",
    "            self.best_epoch = self.current_epoch\n",
    "\n",
    "    def get_eta(self) -> str:\n",
    "        if not self.epoch_times:\n",
    "            return 'Calculating...'\n",
    "        avg_epoch_time = sum(self.epoch_times) / len(self.epoch_times)\n",
    "        remaining_epochs = self.total_epochs - self.current_epoch - 1\n",
    "        return str(timedelta(seconds=int(avg_epoch_time * remaining_epochs)))\n",
    "\n",
    "    def get_speed(self) -> str:\n",
    "        if not self.epoch_times:\n",
    "            return 'N/A'\n",
    "        avg_epoch_time = sum(self.epoch_times) / len(self.epoch_times)\n",
    "        samples_per_sec = (self.train_batches * 32) / avg_epoch_time\n",
    "        return f'{samples_per_sec:.1f} img/s'\n",
    "\n",
    "    def create_dashboard(self, epoch: int, train_loss: float, val_loss: float, val_acc: float, lr: float):\n",
    "        from rich.table import Table\n",
    "        table = Table(title=f'Training Progress - Epoch {epoch+1}/{self.total_epochs}')\n",
    "        table.add_column('Metric', style='cyan', no_wrap=True)\n",
    "        table.add_column('Current', style='magenta')\n",
    "        table.add_column('Best', style='green')\n",
    "        table.add_row('Train Loss', f'{train_loss:.4f}', '-')\n",
    "        table.add_row('Val Loss', f'{val_loss:.4f}', f\"{min(self.val_losses) if self.val_losses else 0:.4f}\")\n",
    "        table.add_row('Val Acc', f'{val_acc:.2f}%', f'{self.best_acc:.2f}% (E{self.best_epoch+1})')\n",
    "        table.add_row('Learning Rate', f'{lr:.2e}', '-')\n",
    "        table.add_row('Speed', self.get_speed(), '-')\n",
    "        table.add_row('ETA', self.get_eta(), '-')\n",
    "        elapsed = str(timedelta(seconds=int(time.time() - self.start_time)))\n",
    "        table.add_row('Elapsed', elapsed, '-')\n",
    "        return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa80d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device & memory management\n",
    "def get_device(force_cpu: bool = False) -> torch.device:\n",
    "    if force_cpu:\n",
    "        return torch.device('cpu')\n",
    "    if torch.backends.mps.is_available():\n",
    "        console.print('✓ MPS device detected - using Apple Silicon GPU acceleration', style='green')\n",
    "        return torch.device('mps')\n",
    "    elif torch.cuda.is_available():\n",
    "        console.print('✓ CUDA device detected', style='green')\n",
    "        return torch.device('cuda')\n",
    "    console.print('⚠️ No GPU found - using CPU', style='yellow')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def clear_memory(device: torch.device):\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "    elif device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e82c1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r18_base',\n",
       " 'r34_base',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b2',\n",
       " 'densenet121']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model configurations\n",
    "MODEL_CONFIGS = {\n",
    "    'r18_base': {'timm_name': 'resnet18', 'input_size': 224, 'batch_size': 32, 'use_custom_head': False},\n",
    "    'r34_base': {'timm_name': 'resnet34', 'input_size': 224, 'batch_size': 24, 'use_custom_head': False},\n",
    "    'efficientnet_b0': {'timm_name': 'efficientnet_b0', 'input_size': 224, 'batch_size': 32, 'use_custom_head': False},\n",
    "    'efficientnet_b1': {'timm_name': 'efficientnet_b1', 'input_size': 240, 'batch_size': 24, 'use_custom_head': False},\n",
    "    'efficientnet_b2': {'timm_name': 'efficientnet_b2', 'input_size': 260, 'batch_size': 16, 'use_custom_head': False},\n",
    "    'densenet121': {'timm_name': 'densenet121', 'input_size': 224, 'batch_size': 24, 'use_custom_head': False},\n",
    "}\n",
    "list(MODEL_CONFIGS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a734b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model head\n",
    "class EnhancedResNetHead(nn.Module):\n",
    "    def __init__(self, in_features: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 512)\n",
    "        self.bn = nn.BatchNorm1d(512)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5b0afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model builder\n",
    "def build_model(variant: str, num_classes: int, use_se: bool = False, pretrained: bool = True):\n",
    "    config = MODEL_CONFIGS[variant]\n",
    "    model_name = config['timm_name']\n",
    "    if use_se and 'resnet' in model_name:\n",
    "        model_name = model_name.replace('resnet', 'seresnet')\n",
    "    model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes if not config.get('use_custom_head') else 0)\n",
    "    if config.get('use_custom_head'):\n",
    "        in_features = model.num_features\n",
    "        model.fc = EnhancedResNetHead(in_features, num_classes)\n",
    "    param_groups = []\n",
    "    if config.get('two_phase'):\n",
    "        backbone_early, backbone_late, head_params = [], [], []\n",
    "        for name, p in model.named_parameters():\n",
    "            if any(k in name for k in ['fc', 'head', 'classifier']):\n",
    "                head_params.append(p)\n",
    "            elif 'layer1' in name or 'layer2' in name:\n",
    "                backbone_early.append(p)\n",
    "            else:\n",
    "                backbone_late.append(p)\n",
    "        param_groups = [\n",
    "            {'params': backbone_early, 'lr_scale': 0.5},\n",
    "            {'params': backbone_late, 'lr_scale': 1.0},\n",
    "            {'params': head_params, 'lr_scale': 1.5},\n",
    "        ]\n",
    "    else:\n",
    "        param_groups = [{'params': model.parameters(), 'lr_scale': 1.0}]\n",
    "    return model, param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1b15d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms\n",
    "def build_transforms(input_size: int, is_training: bool, use_augmentation: bool = True) -> transforms.Compose:\n",
    "    if is_training and use_augmentation:\n",
    "        return create_transform(input_size=input_size, is_training=True, auto_augment='rand-m9-mstd0.5-inc1', interpolation='bicubic', mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225))\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize(int(input_size * 1.14)),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eb336d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preparation\n",
    "def prepare_datasets(data_root: str, val_split: Optional[float], variant: str, use_augmentation: bool = True):\n",
    "    data_path = Path(data_root)\n",
    "    train_path, val_path = data_path / 'train', data_path / 'val'\n",
    "    input_size = MODEL_CONFIGS[variant]['input_size']\n",
    "    train_transform = build_transforms(input_size, True, use_augmentation)\n",
    "    val_transform = build_transforms(input_size, False, False)\n",
    "    if val_path.exists():\n",
    "        train_dataset = datasets.ImageFolder(train_path, transform=train_transform)\n",
    "        val_dataset = datasets.ImageFolder(val_path, transform=val_transform)\n",
    "    else:\n",
    "        full_dataset = datasets.ImageFolder(train_path)\n",
    "        if val_split:\n",
    "            val_size = int(len(full_dataset) * val_split)\n",
    "            train_size = len(full_dataset) - val_size\n",
    "            train_indices, val_indices = random_split(range(len(full_dataset)), [train_size, val_size])\n",
    "            train_dataset = torch.utils.data.Subset(full_dataset, train_indices)\n",
    "            val_dataset = torch.utils.data.Subset(full_dataset, val_indices)\n",
    "            train_dataset.dataset.transform = train_transform\n",
    "            val_dataset.dataset.transform = val_transform\n",
    "        else:\n",
    "            raise ValueError('No validation folder found and val_split not specified')\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9290698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "def create_dataloaders(train_dataset, val_dataset, batch_size: int, num_workers: int = 4, balance_sampler: bool = False):\n",
    "    train_sampler = None\n",
    "    if balance_sampler:\n",
    "        targets = train_dataset.targets if hasattr(train_dataset, 'targets') else [train_dataset.dataset.targets[i] for i in train_dataset.indices]\n",
    "        class_counts = np.bincount(targets)\n",
    "        class_weights = 1.0 / class_counts\n",
    "        sample_weights = [float(class_weights[t]) for t in targets]\n",
    "        train_sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=(train_sampler is None), sampler=train_sampler, num_workers=num_workers, pin_memory=False, persistent_workers=True if num_workers > 0 else False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size*2, shuffle=False, num_workers=num_workers, pin_memory=False, persistent_workers=True if num_workers > 0 else False)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "040cae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM optimizer wrapper\n",
    "class SAM:\n",
    "    def __init__(self, base_optimizer, rho=0.05):\n",
    "        self.base_optimizer = base_optimizer\n",
    "        self.rho = rho\n",
    "    @torch.no_grad()\n",
    "    def first_step(self):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.base_optimizer.param_groups:\n",
    "            scale = self.rho / (grad_norm + 1e-12)\n",
    "            for p in group['params']:\n",
    "                if p.grad is None: continue\n",
    "                p.requires_grad_(False)\n",
    "                p.add_(p.grad * scale)\n",
    "                p.requires_grad_(True)\n",
    "    @torch.no_grad()\n",
    "    def second_step(self):\n",
    "        for group in self.base_optimizer.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None: continue\n",
    "                p.requires_grad_(False)\n",
    "                p.sub_(p.grad * (self.rho / (self._grad_norm() + 1e-12)))\n",
    "                p.requires_grad_(True)\n",
    "        self.base_optimizer.step()\n",
    "    def _grad_norm(self):\n",
    "        return torch.norm(torch.stack([p.grad.norm(p=2) for g in self.base_optimizer.param_groups for p in g['params'] if p.grad is not None]), p=2)\n",
    "    def zero_grad(self):\n",
    "        self.base_optimizer.zero_grad()\n",
    "    @property\n",
    "    def param_groups(self):\n",
    "        return self.base_optimizer.param_groups\n",
    "    def state_dict(self):\n",
    "        return self.base_optimizer.state_dict()\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.base_optimizer.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2866a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training epoch\n",
    "def train_epoch(model, loader, criterion, optimizer, device, scaler, mixup_fn: Optional[Mixup], accumulation_steps: int, use_sam: bool, ema_model: Optional[ModelEmaV2] = None, epoch: int = 0, show_progress: bool = True):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    pbar = tqdm(loader, desc=f'Epoch {epoch+1} [Train]', bar_format='{l_bar}{bar:30}{r_bar}{bar:-10b}', colour='green') if show_progress else loader\n",
    "    for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        if mixup_fn is not None:\n",
    "            inputs, targets = mixup_fn(inputs, targets)\n",
    "        # Forward\n",
    "        if device.type == 'cuda':\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "        else:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "        loss = loss / accumulation_steps\n",
    "        # Backward\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        if (batch_idx + 1) % accumulation_steps == 0:\n",
    "            if use_sam:\n",
    "                optimizer.first_step()\n",
    "                optimizer.zero_grad()\n",
    "                # second forward-backward\n",
    "                if device.type == 'cuda':\n",
    "                    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                        outputs = model(inputs)\n",
    "                        loss2 = criterion(outputs, targets) / accumulation_steps\n",
    "                else:\n",
    "                    outputs = model(inputs)\n",
    "                    loss2 = criterion(outputs, targets) / accumulation_steps\n",
    "                if scaler is not None:\n",
    "                    scaler.scale(loss2).backward()\n",
    "                else:\n",
    "                    loss2.backward()\n",
    "                optimizer.second_step()\n",
    "            else:\n",
    "                if scaler is not None:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if ema_model is not None:\n",
    "                ema_model.update(model)\n",
    "        running_loss += loss.item() * accumulation_steps\n",
    "        if mixup_fn is None:\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        if show_progress and batch_idx % 10 == 0:\n",
    "            current_loss = running_loss / (batch_idx + 1)\n",
    "            current_acc = 100.0 * correct / total if total > 0 else 0.0\n",
    "            if hasattr(pbar, 'set_postfix'):\n",
    "                pbar.set_postfix({'loss': f'{current_loss:.4f}', 'acc': f'{current_acc:.2f}%'})\n",
    "    clear_memory(device)\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    accuracy = 100.0 * correct / total if total > 0 else 0.0\n",
    "    return avg_loss, accuracy, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32ed8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation epoch\n",
    "def validate(model, loader, criterion, device, calc_top5: bool = True, epoch: int = 0, show_progress: bool = True):\n",
    "    model.eval()\n",
    "    running_loss, correct_top1, correct_top5, total = 0.0, 0, 0, 0\n",
    "    pbar = tqdm(loader, desc=f'Epoch {epoch+1} [Val]  ', bar_format='{l_bar}{bar:30}{r_bar}{bar:-10b}', colour='blue') if show_progress else loader\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct_top1 += predicted.eq(targets).sum().item()\n",
    "            if calc_top5:\n",
    "                _, top5_pred = outputs.topk(5, 1, True, True)\n",
    "                correct_top5 += top5_pred.eq(targets.view(-1,1).expand_as(top5_pred)).sum().item()\n",
    "            if show_progress and batch_idx % 10 == 0 and hasattr(pbar, 'set_postfix'):\n",
    "                current_loss = running_loss / (batch_idx + 1)\n",
    "                current_acc = 100.0 * correct_top1 / total\n",
    "                pbar.set_postfix({'loss': f'{current_loss:.4f}', 'acc': f'{current_acc:.2f}%'})\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    top1_acc = 100.0 * correct_top1 / total\n",
    "    top5_acc = 100.0 * correct_top5 / total if calc_top5 else 0.0\n",
    "    return avg_loss, top1_acc, top5_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "560905ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation & visualization\n",
    "def evaluate_model(model, val_loader, device, class_names: List[str], output_dir: Path):\n",
    "    console.print(\"\\n[bold cyan]Running final evaluation...[/bold cyan]\")\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc='Evaluating'):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = outputs.max(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.numpy())\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(output_dir / 'confusion_matrix.png', dpi=150)\n",
    "    plt.close()\n",
    "    report = classification_report(all_targets, all_preds, target_names=class_names[:len(np.unique(all_targets))], output_dict=True)\n",
    "    metrics_df = pd.DataFrame(report).transpose()\n",
    "    metrics_df.to_csv(output_dir / 'per_class_metrics.csv')\n",
    "    summary = {\n",
    "        'accuracy': report['accuracy'],\n",
    "        'macro_avg': report['macro avg'],\n",
    "        'weighted_avg': report['weighted avg'],\n",
    "        'total_samples': len(all_targets)\n",
    "    }\n",
    "    with open(output_dir / 'model_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    console.print(f\"[green]✓ Evaluation complete. Results saved to {output_dir}[/green]\")\n",
    "    console.print(f\"[yellow]  Final Accuracy: {report['accuracy']*100:.2f}%[/yellow]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69dd86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training runner used by the experiments section\n",
    "from types import SimpleNamespace\n",
    "\n",
    "def run_training(args: SimpleNamespace):\n",
    "    # Reproducibility\n",
    "    torch.manual_seed(getattr(args, 'seed', 42))\n",
    "    np.random.seed(getattr(args, 'seed', 42))\n",
    "\n",
    "    # Setup device and output\n",
    "    device = get_device(getattr(args, 'force_cpu', False))\n",
    "    out_root = Path(getattr(args, 'outdir', './runs'))\n",
    "    output_dir = out_root / args.variant\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Persist args\n",
    "    try:\n",
    "        with open(output_dir / 'args.json', 'w') as f:\n",
    "            json.dump(vars(args), f, indent=2)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Data\n",
    "    config = MODEL_CONFIGS[args.variant]\n",
    "    batch_size = getattr(args, 'batch_size', None) or config['batch_size']\n",
    "    train_ds, val_ds = prepare_datasets(\n",
    "        getattr(args, 'data_root', './data'), getattr(args, 'val_split', None), args.variant, not getattr(args, 'no_augs', False)\n",
    "    )\n",
    "    class_names = train_ds.classes if hasattr(train_ds, 'classes') else train_ds.dataset.classes\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    train_loader, val_loader = create_dataloaders(\n",
    "        train_ds, val_ds, batch_size=batch_size, num_workers=getattr(args, 'num_workers', 4), balance_sampler=getattr(args, 'balance_sampler', False)\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    model, param_groups = build_model(args.variant, num_classes, getattr(args, 'use_se', False))\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Optimizer (support per-group lr scaling)\n",
    "    base_lr = float(getattr(args, 'lr', 2e-4))\n",
    "    wd = float(getattr(args, 'weight_decay', 0.1))\n",
    "    opt_param_groups = []\n",
    "    for g in param_groups:\n",
    "        lr_scale = g.pop('lr_scale', 1.0)\n",
    "        opt_param_groups.append({'params': g['params'], 'lr': base_lr * lr_scale})\n",
    "    base_opt = AdamW(opt_param_groups, weight_decay=wd)\n",
    "    use_sam = bool(getattr(args, 'sam', False))\n",
    "    optimizer = SAM(base_opt, rho=0.05) if use_sam else base_opt\n",
    "\n",
    "    # Scheduler (per-epoch)\n",
    "    warmup_epochs = int(getattr(args, 'warmup_epochs', 0))\n",
    "    total_epochs = int(getattr(args, 'epochs', 10))\n",
    "    sched_opt = optimizer.base_optimizer if use_sam else optimizer\n",
    "    scheduler = CosineAnnealingLR(sched_opt, T_max=max(1, total_epochs - warmup_epochs))\n",
    "\n",
    "    # Criterion and mixup/cutmix\n",
    "    mixup_alpha = float(getattr(args, 'mixup', 0.0))\n",
    "    cutmix_alpha = float(getattr(args, 'cutmix', 0.0))\n",
    "    label_smoothing = float(getattr(args, 'label_smoothing', 0.0))\n",
    "    do_aug = not getattr(args, 'no_augs', False)\n",
    "    if do_aug and (mixup_alpha > 0 or cutmix_alpha > 0):\n",
    "        mixup_fn = Mixup(mixup_alpha=mixup_alpha, cutmix_alpha=cutmix_alpha, label_smoothing=label_smoothing, num_classes=num_classes)\n",
    "        criterion = SoftTargetCrossEntropy()\n",
    "    else:\n",
    "        mixup_fn = None\n",
    "        try:\n",
    "            criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "        except TypeError:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # EMA\n",
    "    ema_model = ModelEmaV2(model, decay=0.999) if bool(getattr(args, 'ema', False)) else None\n",
    "\n",
    "    # AMP scaler (CUDA only)\n",
    "    scaler = torch.cuda.amp.GradScaler() if device.type == 'cuda' else None\n",
    "\n",
    "    # Train loop\n",
    "    tracker = TrainingTracker(total_epochs, len(train_loader), len(val_loader))\n",
    "    patience = int(getattr(args, 'patience', 10))\n",
    "    best_top1, patience_ctr = 0.0, 0\n",
    "    metrics = []\n",
    "\n",
    "    # Gradient accumulation to approximate larger batch\n",
    "    eff_bs = 128\n",
    "    accumulation_steps = max(1, eff_bs // batch_size)\n",
    "\n",
    "    console.print(Panel.fit(\n",
    "        f\"Variant: {args.variant}\\nDevice: {device}\\nEpochs: {total_epochs}\\nBatch size: {batch_size} (accum {accumulation_steps})\",\n",
    "        title='Training'\n",
    "    ))\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "        tracker.start_epoch(epoch)\n",
    "\n",
    "        # Warmup LR\n",
    "        if epoch < warmup_epochs:\n",
    "            warmup_scale = (epoch + 1) / float(max(1, warmup_epochs))\n",
    "            for pg in sched_opt.param_groups:\n",
    "                base_group_lr = base_lr  # already scaled above per group when created\n",
    "                # Keep current per-group factor by ratio of current lr to base_lr\n",
    "                scale_factor = pg['lr'] / max(1e-12, base_lr)\n",
    "                pg['lr'] = base_lr * scale_factor * warmup_scale\n",
    "\n",
    "        # Train\n",
    "        train_loss, train_acc, _ = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, scaler, mixup_fn,\n",
    "            accumulation_steps=accumulation_steps, use_sam=use_sam, ema_model=ema_model, epoch=epoch, show_progress=not getattr(args, 'no_progress', False)\n",
    "        )\n",
    "\n",
    "        # Validate (EMA model for eval if present)\n",
    "        eval_model = ema_model.module if ema_model is not None else model\n",
    "        val_loss, val_top1, val_top5 = validate(\n",
    "            eval_model, val_loader, criterion, device, calc_top5=True, epoch=epoch, show_progress=not getattr(args, 'no_progress', False)\n",
    "        )\n",
    "\n",
    "        if epoch >= warmup_epochs:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Track\n",
    "        current_lr = sched_opt.param_groups[0]['lr']\n",
    "        tracker.end_epoch(val_top1)\n",
    "        tracker.train_losses.append(train_loss)\n",
    "        tracker.val_losses.append(val_loss)\n",
    "        tracker.val_accs.append(val_top1)\n",
    "        tracker.lrs.append(current_lr)\n",
    "        console.print(tracker.create_dashboard(epoch, train_loss, val_loss, val_top1, current_lr))\n",
    "\n",
    "        metrics.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'lr': current_lr,\n",
    "            'train_loss': float(train_loss),\n",
    "            'val_loss': float(val_loss),\n",
    "            'top1': float(val_top1),\n",
    "            'top5': float(val_top5),\n",
    "        })\n",
    "\n",
    "        # Early stopping on best top1\n",
    "        if val_top1 > best_top1:\n",
    "            best_top1 = val_top1\n",
    "            patience_ctr = 0\n",
    "        else:\n",
    "            patience_ctr += 1\n",
    "            if patience_ctr >= patience:\n",
    "                console.print(f\"[yellow]Early stopping at epoch {epoch+1}[/yellow]\")\n",
    "                break\n",
    "\n",
    "    # Persist metrics\n",
    "    pd.DataFrame(metrics).to_csv(output_dir / 'metrics_log.tsv', sep='\\t', index=False)\n",
    "\n",
    "    # Final evaluation and artifacts\n",
    "    evaluate_model(eval_model, val_loader, device, class_names, output_dir)\n",
    "\n",
    "    return {'best_acc': float(best_top1), 'output_dir': str(output_dir)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7acc3e",
   "metadata": {},
   "source": [
    "## Run all experiments\n",
    "\n",
    "This section mirrors `run_all_experiments.py` to launch multiple variants sequentially, collect metrics, and write an `EXPERIMENT_SUMMARY.md`. Edit the main Config cell above if you need different data/epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9808ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-all-experiments utilities (inline version of run_all_experiments.py)\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "\n",
    "# Default variants (you can edit this list)\n",
    "VARIANTS = [\n",
    "    \"r18_base\",\n",
    "    \"r34_base\",\n",
    "    \"efficientnet_b0\",\n",
    "    \"efficientnet_b1\",\n",
    "    \"efficientnet_b2\",\n",
    "    \"densenet121\",\n",
    "]\n",
    "\n",
    "@dataclass\n",
    "class ExpBaseConfig:\n",
    "    data_root: str = \"./data\"\n",
    "    epochs: int = 10\n",
    "    num_workers: int = 4\n",
    "    seed: int = 42\n",
    "\n",
    "BASE_CONFIG = ExpBaseConfig()\n",
    "\n",
    "\n",
    "def run_experiment_inline(variant: str) -> dict:\n",
    "    \"\"\"Run a single experiment using the in-notebook training function.\"\"\"\n",
    "    console.print(\"\\n\" + \"=\"*60)\n",
    "    console.print(f\"Starting experiment: {variant}\")\n",
    "    start_ts = time.time()\n",
    "\n",
    "    # Build args for the existing run_training function\n",
    "    from types import SimpleNamespace\n",
    "    base_bs = MODEL_CONFIGS[variant][\"batch_size\"]\n",
    "    args_exp = SimpleNamespace(\n",
    "        variant=variant,\n",
    "        use_se=False,\n",
    "        data_root=BASE_CONFIG.data_root,\n",
    "        val_split=None,\n",
    "        num_workers=BASE_CONFIG.num_workers,\n",
    "        balance_sampler=False,\n",
    "        epochs=BASE_CONFIG.epochs,\n",
    "        batch_size=None,\n",
    "        lr=2e-4,\n",
    "        weight_decay=0.1,\n",
    "        warmup_epochs=3,\n",
    "        patience=10,\n",
    "        no_augs=False,\n",
    "        mixup=0.2,\n",
    "        cutmix=0.2,\n",
    "        label_smoothing=0.1,\n",
    "        ema=(\"plus\" in variant),\n",
    "        sam=(\"plus\" in variant),\n",
    "        freeze_epochs=5,\n",
    "        final_resolution=288,\n",
    "        device='mps',\n",
    "        force_cpu=False,\n",
    "        seed=BASE_CONFIG.seed,\n",
    "        outdir='./runs',\n",
    "        resume=None,\n",
    "        no_progress=False,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        result = run_training(args_exp)\n",
    "        elapsed = time.time() - start_ts\n",
    "\n",
    "        # Read metrics\n",
    "        out_dir = Path(result[\"output_dir\"])  # runs/<variant>\n",
    "        metrics_file = out_dir / 'metrics_log.tsv'\n",
    "        if metrics_file.exists():\n",
    "            mdf = pd.read_csv(metrics_file, sep='\\t')\n",
    "            best_top1 = float(mdf['top1'].max())\n",
    "            best_top5 = float(mdf['top5'].max())\n",
    "            epochs_trained = len(mdf)\n",
    "        else:\n",
    "            best_top1 = 0.0\n",
    "            best_top5 = 0.0\n",
    "            epochs_trained = 0\n",
    "\n",
    "        # Read summary if exists\n",
    "        summary_file = out_dir / 'model_summary.json'\n",
    "        if summary_file.exists():\n",
    "            with open(summary_file) as f:\n",
    "                summary = json.load(f)\n",
    "        else:\n",
    "            summary = {\"accuracy\": best_top1/100.0}\n",
    "\n",
    "        return {\n",
    "            \"variant\": variant,\n",
    "            \"status\": \"completed\",\n",
    "            \"accuracy\": float(summary.get(\"accuracy\", 0.0)) * 100,\n",
    "            \"best_top1\": best_top1,\n",
    "            \"best_top5\": best_top5,\n",
    "            \"epochs_trained\": epochs_trained,\n",
    "            \"training_time\": elapsed,\n",
    "            \"error\": None,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Error training {variant}: {e}[/red]\")\n",
    "        return {\n",
    "            \"variant\": variant,\n",
    "            \"status\": \"error\",\n",
    "            \"accuracy\": 0.0,\n",
    "            \"best_top1\": 0.0,\n",
    "            \"best_top5\": 0.0,\n",
    "            \"epochs_trained\": 0,\n",
    "            \"training_time\": time.time() - start_ts,\n",
    "            \"error\": str(e),\n",
    "        }\n",
    "\n",
    "\n",
    "def generate_summary_md(results: list) -> str:\n",
    "    from datetime import datetime\n",
    "    summary = \"# Aircraft Classification Experiments Summary\\n\\n\"\n",
    "    summary += f\"**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
    "    summary += f\"**Dataset**: 100 Aircraft Classes (80/10/10 split)\\n\"\n",
    "    summary += f\"**Device**: Mac with MPS acceleration (if available)\\n\"\n",
    "    summary += f\"**Epochs**: {BASE_CONFIG.epochs}\\n\\n\"\n",
    "    summary += \"## Performance Comparison\\n\\n\"\n",
    "    summary += \"| Model Variant | Status | Top-1 Acc (%) | Top-5 Acc (%) | Epochs | Time (min) |\\n\"\n",
    "    summary += \"|--------------|---------|---------------|---------------|--------|------------|\\n\"\n",
    "    for r in sorted(results, key=lambda x: x['best_top1'], reverse=True):\n",
    "        status_emoji = \"✅\" if r['status'] == \"completed\" else \"❌\"\n",
    "        time_min = r['training_time'] / 60\n",
    "        summary += f\"| {r['variant']} | {status_emoji} | {r['best_top1']:.2f} | {r['best_top5']:.2f} | {r['epochs_trained']} | {time_min:.1f} |\\n\"\n",
    "    top_completed = [r for r in results if r['status'] == 'completed']\n",
    "    if top_completed:\n",
    "        summary += \"\\n## Top Performers\\n\\n\"\n",
    "        top3 = sorted(top_completed, key=lambda x: x['best_top1'], reverse=True)[:3]\n",
    "        for i, r in enumerate(top3, 1):\n",
    "            summary += f\"{i}. **{r['variant']}**: {r['best_top1']:.2f}% Top-1 accuracy\\n\"\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03dd8bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> Running r18_base </span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36m Running r18_base \u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "============================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "============================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Starting experiment: r18_base\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Starting experiment: r18_base\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ MPS device detected - using Apple Silicon GPU acceleration</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ MPS device detected - using Apple Silicon GPU acceleration\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────── Training ────────╮\n",
       "│ Variant: r18_base        │\n",
       "│ Device: mps              │\n",
       "│ Epochs: 10               │\n",
       "│ Batch size: 32 (accum 4) │\n",
       "╰──────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────── Training ────────╮\n",
       "│ Variant: r18_base        │\n",
       "│ Device: mps              │\n",
       "│ Epochs: 10               │\n",
       "│ Batch size: 32 (accum 4) │\n",
       "╰──────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100%|\u001b[32m██████████████████████████████\u001b[0m| 250/250 [01:47<00:00,  2.32it/s, loss=4.6183, acc=0.00%]\u001b[32m\u001b[0m\n",
      "Epoch 1 [Val]  :   0%|\u001b[34m                              \u001b[0m| 0/16 [00:06<?, ?it/s]\u001b[34m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Error training r18_base: The size of tensor a </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">(</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">64</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">)</span><span style=\"color: #800000; text-decoration-color: #800000\"> must match the size of tensor b </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">(</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">100</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">)</span><span style=\"color: #800000; text-decoration-color: #800000\"> at non-singleton dimension</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mError training r18_base: The size of tensor a \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m64\u001b[0m\u001b[1;31m)\u001b[0m\u001b[31m must match the size of tensor b \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m100\u001b[0m\u001b[1;31m)\u001b[0m\u001b[31m at non-singleton dimension\u001b[0m\n",
       "\u001b[1;31m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Done r18_base: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"color: #008000; text-decoration-color: #008000\">%</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDone r18_base: \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[32m%\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> Running r34_base </span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36m Running r34_base \u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "============================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "============================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Starting experiment: r34_base\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Starting experiment: r34_base\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ MPS device detected - using Apple Silicon GPU acceleration</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ MPS device detected - using Apple Silicon GPU acceleration\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────── Training ────────╮\n",
       "│ Variant: r34_base        │\n",
       "│ Device: mps              │\n",
       "│ Epochs: 10               │\n",
       "│ Batch size: 24 (accum 5) │\n",
       "╰──────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────── Training ────────╮\n",
       "│ Variant: r34_base        │\n",
       "│ Device: mps              │\n",
       "│ Epochs: 10               │\n",
       "│ Batch size: 24 (accum 5) │\n",
       "╰──────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]:  57%|\u001b[32m█████████████████▏            \u001b[0m| 191/334 [02:40<02:00,  1.19it/s, loss=4.6159, acc=0.00%]\u001b[32m\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(VARIANTS, \u001b[32m1\u001b[39m):\n\u001b[32m      6\u001b[39m     console.print(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[i=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Running \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m, style=\u001b[33m\"\u001b[39m\u001b[33mcyan\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     r = \u001b[43mrun_experiment_inline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     all_results.append(r)\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Save intermediate results\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mrun_experiment_inline\u001b[39m\u001b[34m(variant)\u001b[39m\n\u001b[32m     34\u001b[39m args_exp = SimpleNamespace(\n\u001b[32m     35\u001b[39m     variant=variant,\n\u001b[32m     36\u001b[39m     use_se=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     60\u001b[39m     no_progress=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     61\u001b[39m )\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     result = \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs_exp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     elapsed = time.time() - start_ts\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# Read metrics\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 105\u001b[39m, in \u001b[36mrun_training\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    102\u001b[39m         pg[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m] = base_lr * scale_factor * warmup_scale\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m train_loss, train_acc, _ = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmixup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_sam\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_sam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mema_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mema_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mno_progress\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# Validate (EMA model for eval if present)\u001b[39;00m\n\u001b[32m    111\u001b[39m eval_model = ema_model.module \u001b[38;5;28;01mif\u001b[39;00m ema_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, criterion, optimizer, device, scaler, mixup_fn, accumulation_steps, use_sam, ema_model, epoch, show_progress)\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ema_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     49\u001b[39m         ema_model.update(model)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * accumulation_steps\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mixup_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     52\u001b[39m     _, predicted = outputs.max(\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Orchestrate all experiments from the notebook\n",
    "from pprint import pprint\n",
    "\n",
    "all_results = []\n",
    "for i, v in enumerate(VARIANTS, 1):\n",
    "    console.print(f\"\\n[i={i}] Running {v} ...\", style=\"cyan\")\n",
    "    r = run_experiment_inline(v)\n",
    "    all_results.append(r)\n",
    "    # Save intermediate results\n",
    "    with open(\"experiment_results.json\", \"w\") as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    console.print(f\"Done {v}: {r.get('best_top1',0):.2f}%\", style=\"green\")\n",
    "\n",
    "# Summary markdown and a small table view\n",
    "summary_md = generate_summary_md(all_results)\n",
    "with open(\"EXPERIMENT_SUMMARY.md\", \"w\") as f:\n",
    "    f.write(summary_md)\n",
    "\n",
    "pd.DataFrame(all_results).sort_values(\"best_top1\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
