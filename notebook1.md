# Notebook de Clasificaci√≥n de Aeronaves - Multiplataforma (Mac M4 + NVIDIA A100)

Crear un **Jupyter notebook completo** para clasificaci√≥n de im√°genes de aeronaves usando PyTorch + timm. El notebook debe funcionar en **Mac M4 (MPS) y NVIDIA A100 (CUDA)** con detecci√≥n autom√°tica de plataforma y optimizaci√≥n.

**IMPORTANTE: Todo el notebook debe estar en ESPA√ëOL** - comentarios, documentaci√≥n, nombres de variables, texto explicativo, y salidas de print.

## **Especificaciones del Dataset**

- **Ubicaci√≥n del dataset**: directorio `./aviones/`
- **Clases**: 100 clases de aeronaves (estructura ImageFolder)
- **Divisi√≥n de datos**: **80% entrenamiento / 10% validaci√≥n / 10% prueba**
- **Divisi√≥n autom√°tica**: Crear splits train/val/test desde la carpeta `aviones` program√°ticamente

## **Estructura del Notebook (4 Secciones Principales)**

### **1. Configuraci√≥n del Entorno y Verificaci√≥n de GPU**
```python
# Detecci√≥n de plataforma y optimizaci√≥n
# Verificaci√≥n de GPU (MPS/CUDA/CPU)
# Verificaci√≥n de instalaci√≥n de dependencias
# Informaci√≥n de memoria y dispositivo
# Configurar semillas aleatorias para reproducibilidad
# Todo en espa√±ol: print("GPU detectada:", dispositivo)
```

### **2. Definici√≥n de Dataset y Transformaciones**  
```python
# Auto-crear divisi√≥n 80/10/10 train/val/test desde ./aviones/
# Configuraci√≥n de dataset ImageFolder
# Transformaciones adaptativas por plataforma:
#   - Entrenamiento: RandomResizedCrop(224), RandomHorizontalFlip, RandAugment, ColorJitter
#   - Validaci√≥n/Prueba: Resize(256), CenterCrop(224)
# DataLoaders optimizados por plataforma con batch sizes y workers apropiados
# Visualizaci√≥n del dataset y an√°lisis de distribuci√≥n de clases
# Variables y comentarios en espa√±ol: cargador_datos_entrenamiento
```

### **3. Baseline: ResNet-18 (Precisi√≥n Esperada: 55%)**
```python
# Cargar ResNet-18 pre-entrenado desde timm
# Congelar todas las capas (solo extracci√≥n de caracter√≠sticas)
# Entrenar por 10 √©pocas
# Bucle de entrenamiento adaptativo por plataforma con:
#   - Detecci√≥n autom√°tica de dispositivo y optimizaci√≥n
#   - Loss de entrop√≠a cruzada + optimizador Adam
#   - Scheduler coseno con warmup
#   - Seguimiento de progreso y visualizaci√≥n
#   - üìä IMPORTANTE: Guardar m√©tricas en historial_entrenamiento['baseline']
# Evaluaci√≥n en conjunto de validaci√≥n
# Precisi√≥n esperada: ~55%
# Todo documentado en espa√±ol: epoca, precision, perdida

# En cada √©poca del baseline:
guardar_metricas_epoca(historial_entrenamiento, 'baseline', epoca, 
                      loss_entrenamiento, loss_validacion, 
                      precision_entrenamiento, precision_validacion)
```

### **4. ResNet-18 con Unfreezing (Precisi√≥n Esperada: 64%)**
```python  
# Descongelar capas espec√≠ficas: ['layer4', 'fc']
# Tasas de aprendizaje discriminativas:
#   - Capas congeladas: 0 (sin entrenamiento)
#   - layer4: 1e-4  
#   - fc (clasificador): 3e-4
# Entrenar por 10 √©pocas
# Entrenamiento mejorado con:
#   - Optimizaci√≥n espec√≠fica por capa
#   - Monitoreo avanzado
#   - Programaci√≥n de tasa de aprendizaje por grupo de capas
#   - üìä IMPORTANTE: Guardar m√©tricas en historial_entrenamiento['descongelado']
# Evaluaci√≥n final en conjunto de prueba
# Precisi√≥n esperada: ~64%
# Variables en espa√±ol: capas_descongeladas, optimizador_discriminativo

# En cada √©poca del modelo descongelado:
guardar_metricas_epoca(historial_entrenamiento, 'descongelado', epoca, 
                      loss_entrenamiento, loss_validacion, 
                      precision_entrenamiento, precision_validacion)

# Al final del entrenamiento:
crear_graficas_comparativas(historial_entrenamiento)
crear_grafica_loss_combinada(historial_entrenamiento)
exportar_historial_csv(historial_entrenamiento, 'metricas_aeronaves.csv')
```

## **Optimizaciones Multiplataforma**

### **Configuraci√≥n de Dispositivo**
```python
def obtener_configuracion_plataforma():
    if torch.cuda.is_available():
        # Configuraci√≥n NVIDIA A100
        return {
            'dispositivo': 'cuda',
            'tamano_lote': 128,
            'num_trabajadores': 16,
            'pin_memory': True,
            'tasa_aprendizaje': 3e-4
        }
    elif torch.backends.mps.is_available():
        # Configuraci√≥n Mac M4  
        return {
            'dispositivo': 'mps',
            'tamano_lote': 32,
            'num_trabajadores': 4,
            'pin_memory': False,
            'tasa_aprendizaje': 2e-4
        }
    else:
        # Respaldo CPU
        return {
            'dispositivo': 'cpu',
            'tamano_lote': 16,
            'num_trabajadores': 2,
            'pin_memory': False,
            'tasa_aprendizaje': 1e-4
        }
```

## **Requisitos T√©cnicos**

### **Gesti√≥n de Datos**
- **Creaci√≥n autom√°tica de divisi√≥n**: Usar `train_test_split` con estratificaci√≥n
- **Estructura de directorios**: 
  ```
  aviones/
  ‚îú‚îÄ‚îÄ clase_001/
  ‚îú‚îÄ‚îÄ clase_002/
  ‚îî‚îÄ‚îÄ ...
  ```
- **Preservaci√≥n de divisi√≥n**: Guardar √≠ndices de divisi√≥n para experimentos reproducibles

### **Caracter√≠sticas de Entrenamiento**
- **Precisi√≥n mixta**: Implementaci√≥n de AMP apropiada por plataforma
- **Gesti√≥n de memoria**: Limpieza regular de cach√© por plataforma
- **Seguimiento de progreso**: Visualizaciones ricas con matplotlib/seaborn
- **Registro de m√©tricas**: Curvas de precisi√≥n y p√©rdida, matrices de confusi√≥n
- **Checkpointing**: Guardar mejores modelos para cada experimento
- **üìä Guardado de datos para gr√°ficas**: Almacenar historial completo de entrenamiento para visualizaciones posteriores

### **Almacenamiento de Datos de Entrenamiento**
```python
# Estructura para guardar m√©tricas de ambos modelos
historial_entrenamiento = {
    'baseline': {
        'loss_entrenamiento': [],
        'loss_validacion': [],
        'precision_entrenamiento': [],
        'precision_validacion': [],
        'epocas': []
    },
    'descongelado': {
        'loss_entrenamiento': [],
        'loss_validacion': [],
        'precision_entrenamiento': [],
        'precision_validacion': [],
        'epocas': []
    }
}

# Guardar datos en cada √©poca
def guardar_metricas_epoca(historial, modelo_tipo, epoca, loss_train, loss_val, acc_train, acc_val):
    historial[modelo_tipo]['epocas'].append(epoca)
    historial[modelo_tipo]['loss_entrenamiento'].append(loss_train)
    historial[modelo_tipo]['loss_validacion'].append(loss_val)
    historial[modelo_tipo]['precision_entrenamiento'].append(acc_train)
    historial[modelo_tipo]['precision_validacion'].append(acc_val)

# Exportar datos a CSV para an√°lisis posterior
import pandas as pd
def exportar_historial_csv(historial, nombre_archivo='historial_entrenamiento.csv'):
    datos_completos = []
    for modelo in historial.keys():
        for i in range(len(historial[modelo]['epocas'])):
            datos_completos.append({
                'modelo': modelo,
                'epoca': historial[modelo]['epocas'][i],
                'loss_entrenamiento': historial[modelo]['loss_entrenamiento'][i],
                'loss_validacion': historial[modelo]['loss_validacion'][i],
                'precision_entrenamiento': historial[modelo]['precision_entrenamiento'][i],
                'precision_validacion': historial[modelo]['precision_validacion'][i]
            })
    
    df = pd.DataFrame(datos_completos)
    df.to_csv(nombre_archivo, index=False)
    print(f"Historial guardado en: {nombre_archivo}")
```

### **Visualizaci√≥n y An√°lisis**
- **Exploraci√≥n del dataset**: Distribuci√≥n de clases, im√°genes de muestra
- **Monitoreo de entrenamiento**: Gr√°ficos de p√©rdida/precisi√≥n en tiempo real
- **Comparaci√≥n de modelos**: Resultados lado a lado baseline vs descongelado
- **An√°lisis de errores**: Muestras mal clasificadas, rendimiento por clase
- **Resultados finales**: Evaluaci√≥n comprensiva del conjunto de prueba
- **üìà Gr√°ficas comparativas finales**: Curvas Loss vs Epoch para ambos modelos en una sola visualizaci√≥n

### **Funciones de Visualizaci√≥n Comparativa**
```python
def crear_graficas_comparativas(historial):
    """
    Crear gr√°ficas comparativas de Loss vs Epoch para ambos modelos
    """
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # Gr√°fica 1: Loss de Entrenamiento Comparativo
    ax1.plot(historial['baseline']['epocas'], historial['baseline']['loss_entrenamiento'], 
             'b-', label='Baseline ResNet-18', linewidth=2)
    ax1.plot(historial['descongelado']['epocas'], historial['descongelado']['loss_entrenamiento'], 
             'r-', label='ResNet-18 Descongelado', linewidth=2)
    ax1.set_title('P√©rdida de Entrenamiento vs √âpoca', fontsize=14, fontweight='bold')
    ax1.set_xlabel('√âpoca')
    ax1.set_ylabel('P√©rdida')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Gr√°fica 2: Loss de Validaci√≥n Comparativo
    ax2.plot(historial['baseline']['epocas'], historial['baseline']['loss_validacion'], 
             'b--', label='Baseline ResNet-18', linewidth=2)
    ax2.plot(historial['descongelado']['epocas'], historial['descongelado']['loss_validacion'], 
             'r--', label='ResNet-18 Descongelado', linewidth=2)
    ax2.set_title('P√©rdida de Validaci√≥n vs √âpoca', fontsize=14, fontweight='bold')
    ax2.set_xlabel('√âpoca')
    ax2.set_ylabel('P√©rdida')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Gr√°fica 3: Precisi√≥n de Entrenamiento Comparativo
    ax3.plot(historial['baseline']['epocas'], historial['baseline']['precision_entrenamiento'], 
             'b-', label='Baseline ResNet-18', linewidth=2)
    ax3.plot(historial['descongelado']['epocas'], historial['descongelado']['precision_entrenamiento'], 
             'r-', label='ResNet-18 Descongelado', linewidth=2)
    ax3.set_title('Precisi√≥n de Entrenamiento vs √âpoca', fontsize=14, fontweight='bold')
    ax3.set_xlabel('√âpoca')
    ax3.set_ylabel('Precisi√≥n (%)')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Gr√°fica 4: Precisi√≥n de Validaci√≥n Comparativo
    ax4.plot(historial['baseline']['epocas'], historial['baseline']['precision_validacion'], 
             'b--', label='Baseline ResNet-18', linewidth=2)
    ax4.plot(historial['descongelado']['epocas'], historial['descongelado']['precision_validacion'], 
             'r--', label='ResNet-18 Descongelado', linewidth=2)
    ax4.set_title('Precisi√≥n de Validaci√≥n vs √âpoca', fontsize=14, fontweight='bold')
    ax4.set_xlabel('√âpoca')
    ax4.set_ylabel('Precisi√≥n (%)')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('comparacion_modelos.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("‚úÖ Gr√°ficas comparativas guardadas como 'comparacion_modelos.png'")

def crear_grafica_loss_combinada(historial):
    """
    Crear una sola gr√°fica con todas las curvas de p√©rdida
    """
    plt.figure(figsize=(12, 8))
    
    # Curvas de p√©rdida
    plt.plot(historial['baseline']['epocas'], historial['baseline']['loss_entrenamiento'], 
             'b-', label='Baseline - Entrenamiento', linewidth=2)
    plt.plot(historial['baseline']['epocas'], historial['baseline']['loss_validacion'], 
             'b--', label='Baseline - Validaci√≥n', linewidth=2)
    plt.plot(historial['descongelado']['epocas'], historial['descongelado']['loss_entrenamiento'], 
             'r-', label='Descongelado - Entrenamiento', linewidth=2)
    plt.plot(historial['descongelado']['epocas'], historial['descongelado']['loss_validacion'], 
             'r--', label='Descongelado - Validaci√≥n', linewidth=2)
    
    plt.title('Comparaci√≥n de P√©rdida: Baseline vs Descongelado', fontsize=16, fontweight='bold')
    plt.xlabel('√âpoca', fontsize=12)
    plt.ylabel('P√©rdida', fontsize=12)
    plt.legend(fontsize=10)
    plt.grid(True, alpha=0.3)
    
    # A√±adir anotaciones de mejora
    min_loss_baseline = min(historial['baseline']['loss_validacion'])
    min_loss_descongelado = min(historial['descongelado']['loss_validacion'])
    mejora = ((min_loss_baseline - min_loss_descongelado) / min_loss_baseline) * 100
    
    plt.text(0.6, 0.8, f'Mejora en p√©rdida: {mejora:.1f}%', 
             transform=plt.gca().transAxes, fontsize=12, 
             bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
    
    plt.tight_layout()
    plt.savefig('loss_comparativo.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("‚úÖ Gr√°fica de p√©rdida comparativa guardada como 'loss_comparativo.png'")
```

## **Estructura de Celdas del Notebook**

```python
# Celda 1: Configuraci√≥n del entorno e importaciones
import torch, torchvision, timm
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import pickle
# Detecci√≥n de plataforma y configuraci√≥n
# Inicializaci√≥n de historial_entrenamiento
# Todo en espa√±ol: print("Configurando entorno...")

# Celda 2: Preparaci√≥n de datos  
# Auto-crear divisiones train/val/test
# Creaci√≥n de Dataset y DataLoader
# Variables en espa√±ol: conjunto_entrenamiento, cargador_datos

# Celdas 3-N: Entrenamiento ResNet-18 baseline (m√∫ltiples celdas)
# Creaci√≥n del modelo, bucle de entrenamiento, evaluaci√≥n
# üìä Guardado de m√©tricas en cada √©poca: guardar_metricas_epoca()
# Comentarios en espa√±ol: "Iniciando entrenamiento baseline..."

# Celdas N+1-M: Experimento de descongelamiento (m√∫ltiples celdas)  
# Descongelamiento de capas, LRs discriminativos, entrenamiento
# üìä Guardado de m√©tricas en cada √©poca para modelo descongelado
# Variables: modelo_descongelado, capas_entrenables

# Celdas finales: Comparaci√≥n y an√°lisis
# üìà Llamada a crear_graficas_comparativas(historial_entrenamiento)
# üìà Llamada a crear_grafica_loss_combinada(historial_entrenamiento)
# üìÑ Exportaci√≥n a CSV: exportar_historial_csv()
# üíæ Guardado de historial completo en pickle
# Todo documentado en espa√±ol

# Celda final: Resumen de archivos generados
print("üéØ An√°lisis completado!")
print("üìä Gr√°ficas guardadas: comparacion_modelos.png, loss_comparativo.png")
print("üìÑ Datos exportados: metricas_aeronaves.csv")
print("üíæ Modelos guardados: modelo_baseline.pth, modelo_descongelado.pth")
```

## **Salidas Esperadas**

### **Baseline (Secci√≥n 3)**
- Curvas de entrenamiento mostrando convergencia
- Precisi√≥n de validaci√≥n: ~55%
- Matriz de confusi√≥n y m√©tricas por clase
- Checkpoint del modelo guardado
- üìä **Datos guardados**: Historial completo en estructura `historial_entrenamiento['baseline']`
- Mensajes en espa√±ol: "Epoch 1/10 - P√©rdida: 2.45, Precisi√≥n: 23.4%"

### **Modelo Descongelado (Secci√≥n 4)**  
- Visualizaci√≥n de tasas de aprendizaje por capa
- Curvas de entrenamiento con rendimiento mejorado
- Precisi√≥n de prueba: ~64% 
- An√°lisis detallado de errores
- Resumen de comparaci√≥n de modelos
- üìä **Datos guardados**: Historial completo en estructura `historial_entrenamiento['descongelado']`
- üìà **Gr√°ficas comparativas finales**: 
  - Gr√°fica de 4 paneles comparando ambos modelos
  - Gr√°fica combinada de p√©rdida vs √©poca
  - Archivo CSV con todos los datos: `metricas_aeronaves.csv`
- Todo en espa√±ol: "Mejora de precisi√≥n: +9% respecto al baseline"

### **Archivos Generados**
```
üìÅ Salidas del notebook:
‚îú‚îÄ‚îÄ üìä comparacion_modelos.png (4 gr√°ficas en una imagen)
‚îú‚îÄ‚îÄ üìà loss_comparativo.png (gr√°fica combinada de p√©rdida)  
‚îú‚îÄ‚îÄ üìÑ metricas_aeronaves.csv (datos para an√°lisis posterior)
‚îú‚îÄ‚îÄ üíæ modelo_baseline.pth (checkpoint baseline)
‚îú‚îÄ‚îÄ üíæ modelo_descongelado.pth (checkpoint descongelado)
‚îî‚îÄ‚îÄ üîß historial_entrenamiento.pkl (objeto Python completo)
```

## **Installation Requirements**

### **For Mac M4**
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip install timm matplotlib seaborn scikit-learn pandas numpy jupyter
```

### **For NVIDIA A100**
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121  
pip install timm matplotlib seaborn scikit-learn pandas numpy jupyter
```

## **Caracter√≠sticas Principales**

1. **üìä Visualizaciones Ricas**: Gr√°ficos interactivos, barras de progreso, matrices de confusi√≥n
2. **üîÑ Detecci√≥n Autom√°tica de Plataforma**: Funciona sin problemas en Mac M4 o A100
3. **üìà An√°lisis Comprensivo**: Comparaci√≥n detallada de rendimiento y an√°lisis de errores
4. **üéØ Resultados Reproducibles**: Semillas apropiadas y preservaci√≥n de divisiones
5. **üíæ Checkpointing Inteligente**: Guardar y cargar mejores modelos autom√°ticamente
6. **üìù Documentaci√≥n Clara**: Celdas bien comentadas con explicaciones en espa√±ol

**Objetivo**: Notebook completo de Jupyter para clasificaci√≥n de aeronaves que optimiza autom√°ticamente para el hardware disponible mientras proporciona an√°lisis y visualizaci√≥n comprensivos del proceso de entrenamiento. **Todo en idioma espa√±ol.**