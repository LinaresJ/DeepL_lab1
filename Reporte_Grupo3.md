# Reporte de Resultados Preliminares - Clasificaci√≥n de Aeronaves
## Grupo 3

### üìã Resumen Ejecutivo

Este reporte presenta los resultados preliminares de la evaluaci√≥n de diferentes arquitecturas de redes neuronales convolucionales para la clasificaci√≥n de im√°genes de aeronaves. Se evaluaron 8 modelos diferentes utilizando un dataset con 100 clases de aeronaves, con 8,000 im√°genes de entrenamiento y 1,000 de validaci√≥n.

### üéØ Objetivos

- Comparar el rendimiento de diferentes arquitecturas de CNN modernas
- Identificar el modelo con mejor balance entre precisi√≥n y eficiencia
- Evaluar la convergencia de los modelos con entrenamiento extendido (30 √©pocas intentadas)
- Implementar entrenamiento con t√©cnicas avanzadas de optimizaci√≥n

### üìä Resultados Obtenidos

#### Tabla Comparativa de Rendimiento

| Modelo | √âpocas | Top-1 Accuracy (Val) | Top-5 Accuracy (Val) | Estado | Observaciones |
|--------|---------|---------------------|---------------------|---------|---------------|
| **EfficientNet-B1** | 3 | **70.70%** | **92.40%** | ‚úÖ Exitoso | Mejor rendimiento general (entrenamiento inicial) |
| **EfficientNet-B2** | 3 | **68.00%** | **90.50%** | ‚úÖ Exitoso | Segundo mejor (entrenamiento inicial) |
| **DenseNet-121** | 3 | **61.70%** | **86.80%** | ‚úÖ Exitoso | Buen rendimiento (entrenamiento inicial) |
| **EfficientNet-B0** | 3 | **51.60%** | **83.50%** | ‚úÖ Exitoso | Modelo m√°s liviano |
| **EfficientNet-B1** | 30 | - | - | ‚ùå Falla t√©cnica | Error en funci√≥n de p√©rdida durante validaci√≥n |
| **EfficientNet-B2** | 30 | - | - | ‚ùå Falla t√©cnica | Error en funci√≥n de p√©rdida durante validaci√≥n |
| **DenseNet-121** | 30 | - | - | ‚ùå Falla t√©cnica | Error en funci√≥n de p√©rdida durante validaci√≥n |
| **ResNet-34 Plus** | 3 | 1.30% | 5.40% | ‚úÖ Convergencia lenta | Necesita m√°s √©pocas |
| **ResNet-18 Plus** | 3 | 0.70% | 4.50% | ‚úÖ Convergencia lenta | Necesita m√°s √©pocas |

#### Configuraciones de Entrenamiento

| Modelo | Batch Size | Input Size | Grad. Accumulation | EMA |
|--------|------------|------------|-------------------|-----|
| EfficientNet-B0 | 32 | 224√ó224 | 4 steps | No |
| EfficientNet-B1 | 24 | 240√ó240 | 5 steps | No |
| EfficientNet-B2 | 16 | 260√ó260 | 8 steps | No |
| DenseNet-121 | 24 | 224√ó224 | 5 steps | No |
| ResNet-18 Plus | 32 | 224√ó224 | 4 steps | S√≠ |
| ResNet-34 Plus | 24 | 224√ó224 | 5 steps | S√≠ |

### üîß Definiciones de Modelos

#### EfficientNet-B1
- **Arquitectura**: EfficientNet-B1 con escalado compuesto de profundidad, anchura y resoluci√≥n
- **Par√°metros**: ~7.8M par√°metros
- **Entrada**: 240√ó240 p√≠xeles
- **Caracter√≠sticas**: 
  - Arquitectura basada en Neural Architecture Search (NAS)
  - Uso de bloques MBConv con Squeeze-and-Excitation
  - Escalado eficiente de todos los componentes de la red

#### EfficientNet-B2
- **Arquitectura**: EfficientNet-B2 con mayor resoluci√≥n y capacidad que B1
- **Par√°metros**: ~9.2M par√°metros
- **Entrada**: 260√ó260 p√≠xeles
- **Caracter√≠sticas**:
  - Mayor profundidad y anchura que EfficientNet-B1
  - Mejor capacidad de representaci√≥n a costa de m√°s recursos computacionales
  - Activaciones Swish para mejor gradiente

#### DenseNet-121
- **Arquitectura**: DenseNet con 121 capas y conexiones densas
- **Par√°metros**: ~8.0M par√°metros
- **Entrada**: 224√ó224 p√≠xeles
- **Caracter√≠sticas**:
  - Conexiones densas entre todas las capas
  - Reutilizaci√≥n eficiente de caracter√≠sticas
  - Reducci√≥n del problema de gradiente desvaneciente

### üìà An√°lisis de Resultados

#### üèÜ Modelos Exitosos

1. **EfficientNet-B1** (Ganador)
   - **Precisi√≥n Top-1**: 70.70%
   - **Precisi√≥n Top-5**: 92.40%
   - Excelente convergencia en solo 3 √©pocas
   - Balance √≥ptimo entre complejidad y rendimiento

2. **EfficientNet-B2**
   - **Precisi√≥n Top-1**: 68.00%
   - **Precisi√≥n Top-5**: 90.50%
   - Rendimiento muy competitivo
   - Requiere m√°s recursos computacionales

3. **DenseNet-121**
   - **Precisi√≥n Top-1**: 61.70%
   - **Precisi√≥n Top-5**: 86.80%
   - Arquitectura robusta con buena generalizaci√≥n
   - Convergencia estable

#### ‚ö†Ô∏è Modelos con Dificultades

1. **Familia ResNet**
   - Los modelos ResNet mostraron convergencia muy lenta
   - Diferencia significativa entre precisi√≥n de validaci√≥n y test
   - **ResNet-18 Base** fall√≥ por error dimensional
   - Requieren mayor n√∫mero de √©pocas para convergencia adecuada

#### üîß Desaf√≠os T√©cnicos Encontrados

1. **Entrenamiento Extendido (30 √©pocas)**
   - **Problema**: Error en la funci√≥n de p√©rdida durante la fase de validaci√≥n
   - **Error espec√≠fico**: Incompatibilidad entre `SoftTargetCrossEntropy` (usado para Mixup) y targets regulares en validaci√≥n
   - **S√≠ntoma**: Falla despu√©s del primer epoch durante `validate()` en `loss = criterion(outputs, targets)`
   - **Impacto**: Imposibilit√≥ completar el entrenamiento extendido para los tres modelos principales

2. **Configuraci√≥n de Mixup/Augmentation**
   - El script usa `SoftTargetCrossEntropy` cuando Mixup est√° habilitado
   - En validaci√≥n se esperan targets regulares (enteros) pero la funci√≥n de p√©rdida espera distribuciones suaves
   - Requiere separaci√≥n de criterios de p√©rdida para entrenamiento y validaci√≥n

### üîç Observaciones T√©cnicas

#### Convergencia y Aprendizaje

- **EfficientNet**: Familia que mostr√≥ la mejor convergencia con r√°pida mejora desde la primera √©poca
- **DenseNet**: Convergencia progresiva y estable a lo largo de las √©pocas
- **ResNet**: Convergencia extremadamente lenta, sugiriendo necesidad de:
  - Mayor n√∫mero de √©pocas
  - Ajuste de hiperpar√°metros
  - Revisi√≥n de la implementaci√≥n

#### Errores Identificados

1. **ResNet-18 Base**: Error dimensional en tensores (64 vs 100)
   - Posible problema en la capa de clasificaci√≥n final
   - Requiere revisi√≥n de la arquitectura

### üìã Configuraci√≥n Experimental

- **Dataset**: 100 clases de aeronaves
- **Entrenamiento**: 8,000 im√°genes
- **Validaci√≥n**: 1,000 im√°genes  
- **√âpocas**: 3 (entrenamiento preliminar exitoso), 30 (intentado, fallas t√©cnicas)
- **Hardware**: Apple Silicon GPU (MPS)
- **Optimizaci√≥n**: Gradient accumulation, Mixup, CutMix, EMA (para modelos Plus)
- **T√©cnicas Avanzadas**: SAM optimizer, Cosine Annealing LR, AutoAugment

### üéØ Conclusiones y Recomendaciones

#### Conclusiones Principales

1. **EfficientNet-B1** demostr√≥ ser el modelo m√°s efectivo para esta tarea
2. La familia **EfficientNet** super√≥ consistentemente a otras arquitecturas
3. **DenseNet-121** ofrece un buen balance como alternativa
4. Los modelos **ResNet** requieren optimizaci√≥n adicional

#### Recomendaciones para Trabajo Futuro

1. **Resoluci√≥n de Problemas T√©cnicos**
   - **Prioridad Alta**: Corregir incompatibilidad de funci√≥n de p√©rdida en validaci√≥n
   - Implementar criterios de p√©rdida separados para entrenamiento (SoftTargetCrossEntropy) y validaci√≥n (CrossEntropyLoss)
   - Verificar manejo correcto de targets en modo validaci√≥n

2. **Entrenamiento Extendido Exitoso**
   - Una vez corregidos los errores t√©cnicos, completar entrenamiento de 30 √©pocas
   - Implementar early stopping basado en validaci√≥n
   - Monitorear curvas de aprendizaje para detectar overfitting

3. **Optimizaciones para ResNet**
   - Revisar implementaci√≥n de ResNet-18 Base
   - Ajustar learning rate espec√≠ficamente para familia ResNet
   - Considerar warm-up learning rate schedule m√°s largo

4. **Mejoras en Pipeline de Entrenamiento**
   - Implementar manejo robusto de errores durante entrenamiento
   - Agregar checkpoints autom√°ticos para recovery
   - Mejorar logging y monitoreo de m√©tricas

5. **An√°lisis Extendido**
   - Generar curvas de entrenamiento para todos los modelos exitosos
   - Implementar an√°lisis de matriz de confusi√≥n detallada
   - Evaluar en dataset de test independiente una vez completado el entrenamiento

### üìä M√©tricas de Eficiencia

| Modelo | Par√°metros Aprox. | Tiempo/√âpoca | Memoria GPU |
|--------|-------------------|--------------|-------------|
| EfficientNet-B0 | 5.3M | R√°pido | Bajo |
| EfficientNet-B1 | 7.8M | Medio | Medio |
| EfficientNet-B2 | 9.2M | Medio-Alto | Alto |
| DenseNet-121 | 8.0M | Medio | Medio |

---

### üë• Informaci√≥n del Grupo

**Grupo 3**  
**Proyecto**: Clasificaci√≥n de Aeronaves con Deep Learning  
**Fecha**: Agosto 2025  
**Estado**: Resultados Preliminares - 3 √âpocas + An√°lisis T√©cnico de Fallas en 30 √âpocas

---

*Este reporte presenta resultados exitosos de entrenamiento preliminar (3 √©pocas) y an√°lisis detallado de las fallas t√©cnicas encontradas durante los intentos de entrenamiento extendido (30 √©pocas). Los mejores modelos (EfficientNet-B1, B2, DenseNet-121) demostraron excelente rendimiento inicial que justifica la resoluci√≥n de los problemas t√©cnicos para entrenamiento completo.*